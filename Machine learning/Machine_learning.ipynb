{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content \n",
    "* Data Cleansing\n",
    "  * Removing urls, emojis, and @ABCD.\n",
    "  * Data Normalization\n",
    "  * Removing (Ø§Ù„Ù‡Ù…Ø²Ø© ÙˆØ§Ù„Ù†Ù‚Ø§Ø· Ù…Ù† ÙÙˆÙ‚ Ø§Ù„ØªØ§Ø¡ Ø§Ù„Ù…Ø±Ø¨ÙˆØ·Ø©).\n",
    "* Data Preprocessing \n",
    "  * Tokenization.\n",
    "  * Tfidftransformer\n",
    "* Modeling and training \n",
    "  * Define Models.\n",
    "  * Training \n",
    "  * Evaluation \n",
    "  * Loading Model,and Transformer for future use.\n",
    "  * Test model's predictability \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:49:25.761220Z",
     "iopub.status.busy": "2022-03-13T17:49:25.760894Z",
     "iopub.status.idle": "2022-03-13T17:49:27.285618Z",
     "shell.execute_reply": "2022-03-13T17:49:27.283899Z",
     "shell.execute_reply.started": "2022-03-13T17:49:25.761135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All SET\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import pickle \n",
    "import numpy as np\n",
    "from helper import text_normalize,tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"All SET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Eslam\\\\OneDrive\\\\Desktop\\\\AIM Technologies\\\\Machine learning'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:49:56.438766Z",
     "iopub.status.busy": "2022-03-13T17:49:56.438466Z",
     "iopub.status.idle": "2022-03-13T17:49:59.513621Z",
     "shell.execute_reply": "2022-03-13T17:49:59.512722Z",
     "shell.execute_reply.started": "2022-03-13T17:49:56.438738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  \\\n",
       "0  1175358310087892992      IQ   \n",
       "1  1175416117793349632      IQ   \n",
       "2  1175450108898565888      IQ   \n",
       "3  1175471073770573824      IQ   \n",
       "4  1175496913145217024      IQ   \n",
       "\n",
       "                                                text  \n",
       "0   @Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .  \n",
       "1  @7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...  \n",
       "2                    @KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ  \n",
       "3         @HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’  \n",
       "4                 @hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\Eslam\\\\OneDrive\\\\Desktop\\\\AIM Technologies\\\\Data Fetching\\\\Data Fetching\\\\dataset.csv',encoding='UTF-32')\n",
    "print(\"Data imported\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing\n",
    "* Removing urls, emoji, and twitter usernames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:50:56.926293Z",
     "iopub.status.busy": "2022-03-13T17:50:56.925808Z",
     "iopub.status.idle": "2022-03-13T17:50:56.932461Z",
     "shell.execute_reply": "2022-03-13T17:50:56.931589Z",
     "shell.execute_reply.started": "2022-03-13T17:50:56.926245Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    \"\"\"\n",
    "    The data preprocessing fuction takes string, extracts only arabic text out of it,\n",
    "    removes Ø§Ù„Ù‡Ù…Ø²Ø© ÙˆØ§Ù„ØªØ§Ø¡ Ø§Ù„Ù…Ø±Ø¨ÙˆØ·Ø©\n",
    "    Input >>> text\n",
    "    Output >>> clean text\n",
    "    \"\"\"\n",
    "    text=re.sub(r'[^\\s\\u0627-\\u064a]','', text)\n",
    "    text=re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    text=text_normalize(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:50:57.985472Z",
     "iopub.status.busy": "2022-03-13T17:50:57.984933Z",
     "iopub.status.idle": "2022-03-13T17:51:10.778012Z",
     "shell.execute_reply": "2022-03-13T17:51:10.777217Z",
     "shell.execute_reply.started": "2022-03-13T17:50:57.985435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠÙ‡ ÙŠÙ†ØªÙØ¶ ÙŠØºÙŠØ±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„ÙŠ Ø§Ù„Ø¨Ø´Ø± Ø­ÙŠÙˆÙ†Ù‡ ÙˆØ­Ø´ÙŠÙ‡ ÙˆØªØ·Ù„Ø¨ÙˆÙ† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡ Ø§Ø® Ù…Ø­Ù…Ø¯</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  \\\n",
       "0  1175358310087892992      IQ   \n",
       "1  1175416117793349632      IQ   \n",
       "2  1175450108898565888      IQ   \n",
       "3  1175471073770573824      IQ   \n",
       "4  1175496913145217024      IQ   \n",
       "\n",
       "                                                text  \n",
       "0                           Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠÙ‡ ÙŠÙ†ØªÙØ¶ ÙŠØºÙŠØ±   \n",
       "1   ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„ÙŠ Ø§Ù„Ø¨Ø´Ø± Ø­ÙŠÙˆÙ†Ù‡ ÙˆØ­Ø´ÙŠÙ‡ ÙˆØªØ·Ù„Ø¨ÙˆÙ† ...  \n",
       "2                                Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ  \n",
       "3                          ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡  \n",
       "4                             ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡ Ø§Ø® Ù…Ø­Ù…Ø¯   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['text'].apply(preprocessing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sounds good the data is now clean and normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tfidftransformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:53:36.179802Z",
     "iopub.status.busy": "2022-03-13T17:53:36.178931Z",
     "iopub.status.idle": "2022-03-13T17:55:58.896713Z",
     "shell.execute_reply": "2022-03-13T17:55:58.895691Z",
     "shell.execute_reply.started": "2022-03-13T17:53:36.179756Z"
    }
   },
   "outputs": [],
   "source": [
    "Tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
    "Tfidf_transformer = Tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:56:06.515191Z",
     "iopub.status.busy": "2022-03-13T17:56:06.514896Z",
     "iopub.status.idle": "2022-03-13T17:56:07.122316Z",
     "shell.execute_reply": "2022-03-13T17:56:07.121484Z",
     "shell.execute_reply.started": "2022-03-13T17:56:06.515161Z"
    }
   },
   "outputs": [],
   "source": [
    "len(Tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:56:32.246677Z",
     "iopub.status.busy": "2022-03-13T17:56:32.246322Z",
     "iopub.status.idle": "2022-03-13T17:56:32.910111Z",
     "shell.execute_reply": "2022-03-13T17:56:32.909243Z",
     "shell.execute_reply.started": "2022-03-13T17:56:32.246645Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the first vector out (for the first document) \n",
    "first_vector_tfidfvectorizer=Tfidf_transformer[0]\n",
    "# place tf-idf values in a pandas data frame \n",
    "dt = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=Tfidf.get_feature_names(), columns=[\"tfidf\"])\n",
    "print(df['text'][0])\n",
    "dt[dt['tfidf']>0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:56:47.801857Z",
     "iopub.status.busy": "2022-03-13T17:56:47.800969Z",
     "iopub.status.idle": "2022-03-13T17:56:47.840455Z",
     "shell.execute_reply": "2022-03-13T17:56:47.839669Z",
     "shell.execute_reply.started": "2022-03-13T17:56:47.801791Z"
    }
   },
   "outputs": [],
   "source": [
    "df['dialect'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:57:19.405010Z",
     "iopub.status.busy": "2022-03-13T17:57:19.404669Z",
     "iopub.status.idle": "2022-03-13T17:57:19.411718Z",
     "shell.execute_reply": "2022-03-13T17:57:19.410836Z",
     "shell.execute_reply.started": "2022-03-13T17:57:19.404973Z"
    }
   },
   "outputs": [],
   "source": [
    "dialect_mapping={'IQ':0, 'LY':1, 'QA':2, 'PL':3, 'SY':4, 'TN':5, 'JO':6, 'MA':7, 'SA':8, 'YE':9,\n",
    "                 'DZ':10,'EG':11, 'LB':11, 'KW':13, 'OM':14, 'SD':15, 'AE':16, 'BH':17}\n",
    "# reverse the dict to return the label as text not number \n",
    "y_id_to_word = {value: key for key, value in dialect_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:57:25.284083Z",
     "iopub.status.busy": "2022-03-13T17:57:25.283778Z",
     "iopub.status.idle": "2022-03-13T17:57:25.355853Z",
     "shell.execute_reply": "2022-03-13T17:57:25.354718Z",
     "shell.execute_reply.started": "2022-03-13T17:57:25.284054Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=df['dialect'].map(dialect_mapping)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:57:35.124339Z",
     "iopub.status.busy": "2022-03-13T17:57:35.124037Z",
     "iopub.status.idle": "2022-03-13T17:57:35.227266Z",
     "shell.execute_reply": "2022-03-13T17:57:35.226363Z",
     "shell.execute_reply.started": "2022-03-13T17:57:35.124307Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(Tfidf_transformer, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:15:28.210334Z",
     "iopub.status.busy": "2022-03-13T16:15:28.209954Z",
     "iopub.status.idle": "2022-03-13T16:15:28.887502Z",
     "shell.execute_reply": "2022-03-13T16:15:28.886837Z",
     "shell.execute_reply.started": "2022-03-13T16:15:28.210306Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(train_x, train_y)\n",
    "y_score = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:15:28.889140Z",
     "iopub.status.busy": "2022-03-13T16:15:28.888769Z",
     "iopub.status.idle": "2022-03-13T16:15:29.157419Z",
     "shell.execute_reply": "2022-03-13T16:15:29.156609Z",
     "shell.execute_reply.started": "2022-03-13T16:15:28.889112Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(test_y, y_score,target_names=['IQ', 'LY', 'QA', 'PL', 'SY', 'TN', 'JO', 'MA', 'SA', 'YE', 'DZ',\n",
    "       'EG', 'LB', 'KW', 'OM', 'SD', 'AE', 'BH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:15:29.158821Z",
     "iopub.status.busy": "2022-03-13T16:15:29.158598Z",
     "iopub.status.idle": "2022-03-13T16:32:27.958622Z",
     "shell.execute_reply": "2022-03-13T16:32:27.957652Z",
     "shell.execute_reply.started": "2022-03-13T16:15:29.158793Z"
    }
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(max_iter=10000)\n",
    "lr.fit(train_x, train_y)\n",
    "yhat=lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:32:27.960163Z",
     "iopub.status.busy": "2022-03-13T16:32:27.959924Z",
     "iopub.status.idle": "2022-03-13T16:32:28.268052Z",
     "shell.execute_reply": "2022-03-13T16:32:28.267200Z",
     "shell.execute_reply.started": "2022-03-13T16:32:27.960133Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_y, yhat,target_names=['IQ', 'LY', 'QA', 'PL', 'SY', 'TN', 'JO', 'MA', 'SA', 'YE', 'DZ',\n",
    "       'EG', 'LB', 'KW', 'OM', 'SD', 'AE', 'BH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression performance is way better than the Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:43:16.150795Z",
     "iopub.status.busy": "2022-03-13T17:43:16.150149Z",
     "iopub.status.idle": "2022-03-13T17:43:16.724072Z",
     "shell.execute_reply": "2022-03-13T17:43:16.723186Z",
     "shell.execute_reply.started": "2022-03-13T17:43:16.150749Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('logistic_regression.pickle','wb') as model:\n",
    "    pickle.dump(lr,model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:58:38.842663Z",
     "iopub.status.busy": "2022-03-13T17:58:38.842079Z",
     "iopub.status.idle": "2022-03-13T17:58:39.278863Z",
     "shell.execute_reply": "2022-03-13T17:58:39.277907Z",
     "shell.execute_reply.started": "2022-03-13T17:58:38.842623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eslam\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#testing the performance \n",
    "model=pickle.load(open('./logistic_regression.pickle','rb'))\n",
    "transformer=pickle.load(open('./Tfidf.pickle','rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:58:09.720668Z",
     "iopub.status.busy": "2022-03-13T17:58:09.720310Z",
     "iopub.status.idle": "2022-03-13T17:58:09.727581Z",
     "shell.execute_reply": "2022-03-13T17:58:09.726889Z",
     "shell.execute_reply.started": "2022-03-13T17:58:09.720631Z"
    }
   },
   "outputs": [],
   "source": [
    "def predcitor(text):\n",
    "    \"\"\"\n",
    "    this function takes text and returns the dialect\n",
    "    it normalizes the entered text and use it to predict the dialect.\n",
    "    \"\"\"\n",
    "    y_id_to_word={1:'IQ',2: 'LY',3: 'QA',4: 'PL',5: 'SY',6: 'TN',7: 'JO',8: 'MA',9: 'SA',10: 'YE',11: 'DZ',12: 'EG',13: 'LB',14: 'KW',15: 'OM',16: 'SD',17: 'AE',18: 'BH'}\n",
    "    text=preprocessing(text)\n",
    "    text=text.split(\" \")\n",
    "    return y_id_to_word[np.argmax(model.predict(transformer.transform(text)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T17:58:10.991318Z",
     "iopub.status.busy": "2022-03-13T17:58:10.990834Z",
     "iopub.status.idle": "2022-03-13T17:58:11.043835Z",
     "shell.execute_reply": "2022-03-13T17:58:11.042976Z",
     "shell.execute_reply.started": "2022-03-13T17:58:10.991269Z"
    }
   },
   "outputs": [],
   "source": [
    "pred=predcitor('ØµØ¨Ø§Ø­ Ø§Ù„Ø¹Ø³Ù„')\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(transformer.transform('Ø§Ø¨Ùˆ ØµÙ„Ø§Ø­ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ'.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
